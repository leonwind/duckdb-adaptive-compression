\documentclass{beamer}
\usepackage{caption}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{booktabs}
\usepackage{listings}
\usepackage{pgf}

\lstdefinestyle{C++}{language=C++,
                showstringspaces=false,
                basicstyle=\ttfamily,
                morekeywords={size_t,size_in_bytes,bit_compress,extractMinFromVector,width},
                keywordstyle=\color{blue}\ttfamily,
                stringstyle=\color{red}\ttfamily,
                commentstyle=\color{green}\ttfamily,
                morecomment=[l][\color{magenta}]{\#}
}
\lstdefinestyle{shell}{basicstyle=\ttfamily}
\lstdefinestyle{SQL}{language=SQL,basicstyle=\ttfamily, keywordstyle=\color{blue}\ttfamily}


\title{(Not yet Adaptive) Compression of In-Memory Databases}
\subtitle{Database Implementation Lab Course}
\author{Leon Windheuser}
\date{March 14, 2023}


\begin{document}

\frame{\titlepage}


\begin{frame}
    \frametitle{Project Introduction}
    We want to compress the transient part of DuckDB
    %\vspace{1cm}
    \pause

    \begin{itemize}
        \item Open Source SQL OLAP RDBMS in-process developed in Amsterdam research centre CWI (SQLite for OLAP)
        \url{https://github.com/duckdb/duckdb}
        \item Columnar Storage format
        \item Vectorized execution engine
        \item Has already lots of different compression possibilities for persistent data on disk 
    \end{itemize}

    \vspace{1cm}
    \pause
    \centering
    \textbf{How do we compress the transient data while having efficient lookups without decompressing everything?}
\end{frame}


\begin{frame}
    \frametitle{Background: Succinct Data Structures}
    
    \begin{itemize}
        \item Data structures which uses space close to the theoretic
            lower bound but allows efficient query operations (in-place without needing to decompress)
        \item Exists for e.g. {\only<+>{(bit) vectors}\only<+->{\textbf{(bit) vectors}}}, trees, planar graphs, ...
    \end{itemize}
\end{frame}

% Example in db: Primary key and Enums (4 bytes but only 17 categories)
\begin{frame}
    \frametitle{Succinct Integer Vector}
    \centering
    Space requirement for integer $x$ is $\ell = \lfloor \log_2(x) \rfloor + 1$ bits

    \includegraphics[width=\framewidth]{figures/excalidraw/bit-int-vector.png}
    \pause

    Encode integers with the minimal length of the max integer $3 = \lfloor \log_2(7) \rfloor + 1$ \\
    \vspace{0.5cm} 
    \includegraphics[width=0.75\framewidth]{figures/excalidraw/bit-compressed-int-vector.png}

    \vspace{0.5cm}
    \textbf{We already reduce memory by 25\%}
\end{frame}


\begin{frame}
    \frametitle{SDSL: Succinct Data Structure Library}

    \begin{itemize}
        \item C++11 library and abstraction for succinct data structures
        \item Open Source \url{https://github.com/simongog/sdsl-lite}
        \item Contains varierty of different data structures. For now we only used the \textbf{Integer Vectors}.
    \end{itemize}
\end{frame}


\begin{frame}[fragile]
    \frametitle{SDSL: Integer Vectors}

\begin{lstlisting}[style=C++,escapechar=!]
sdsl::int_vector<32> v(10000);
for (size_t i = 0; i < 10000; i++) v[i] = i;
cout << "Width: " << v.width() << ", size: " 
     << sdsl::size_in_bytes(v) << endl;
!\colorbox{yellow}{sdsl::util::bit\_compress(v);}!
cout << "Width: " << v.width() << ", size: " 
     << sdsl::size_in_bytes(v) << endl;
\end{lstlisting}

\pause

\begin{lstlisting}[style=shell]
Width: 32, size: 40008
Width: 14, size: 17513
\end{lstlisting}

\pause

\begin{center}
    Reduces memory by 56.2\% ($\approx$ 22.5 KB)
\end{center}
\end{frame}


\begin{frame}[fragile]
    \frametitle{Delta compression of \ttfamily{sdsl::int\_vector}}

\begin{lstlisting}[style=C++]
sdsl::int_vector<32> v(10000);
for (size_t i = 0; i < 10000; i++) 
    v[i] = i + 10.000.000;
cout << "Width: " << v.width() << ", size: " 
     << sdsl::size_in_bytes(v) << endl;
sdsl::util::bit_compress(v);
cout << "Width: " << v.width() << ", size: " 
     << sdsl::size_in_bytes(v) << endl;
\end{lstlisting}

\begin{lstlisting}[style=shell]
Width: 32, size: 40008
Width: 24, size: 30008
\end{lstlisting}
\end{frame}


\begin{frame}[fragile]
    \frametitle{Delta compression of \ttfamily{sdsl::int\_vector}}
\begin{lstlisting}[style=C++,escapechar=!]
sdsl::int_vector<32> v(10000);
for (size_t i = 0; i < 10000; i++) 
    v[i] = i + 10.000.000;
cout << "Width: " << v.width() << ", size: " 
     << sdsl::size_in_bytes(v) << endl;
!\colorbox{yellow}{extractMinFromVector(v);}!
sdsl::util::bit_compress(v);
cout << "Width: " << v.width() << ", size: " 
     << sdsl::size_in_bytes(v) << endl;
\end{lstlisting}

\begin{lstlisting}[style=shell]
Width: 32, size: 40008
Width: 14, size: 17513
\end{lstlisting}

\pause
In DuckDB we know the minimum of the vector directly without searching (column statistics)
\end{frame}


\begin{frame}
    \frametitle{DuckDB Storage Architecture 100 meter view}
    \includegraphics[width=\framewidth]{figures/excalidraw/duckdb-high-level-storage-arch.png}
\end{frame}


\begin{frame}
    \frametitle{DuckDB Storage Architecture 10 meter view}
    \includegraphics[width=\framewidth]{figures/excalidraw/duckdb-column-segment-look.png}

\end{frame}


\begin{frame}[fragile]
    \frametitle{Benchmarks: Sequential Insert and total Scan}
Scanning $10^6$ rows.

\begin{lstlisting}[style=SQL]
SELECT * FROM t1;
\end{lstlisting}

    \input{../experiments/plots/pgf/Total_Memory_of_SequentialInsert.pgf}
\end{frame}


\begin{frame}[fragile]
    \frametitle{Benchmarks: Sequential Insert and total Scan}
Scanning $10^6$ rows.

\begin{lstlisting}[style=SQL]
SELECT * FROM t1;
\end{lstlisting}

    \input{../experiments/plots/pgf/Runtime_of_SequentialInsert.pgf}
\end{frame}


\begin{frame}[fragile]
    \frametitle{Benchmarks: Zipf Selection}
10.000 selections with Zipf Distribution of $10^6$ total rows.

\begin{lstlisting}[style=SQL]
SELECT i FROM t1 
WHERE i == {ZIPF_DISTRIBUTED_NUMBER};
\end{lstlisting}

    \input{../experiments/plots/pgf/Total_Memory_of_ZipfDistribution.pgf}
\end{frame}


\begin{frame}[fragile]
    \frametitle{Benchmarks: Zipf Selection}
10.000 selections with Zipf Distribution of $10^6$ total rows.

\begin{lstlisting}[style=SQL]
SELECT i FROM t1 
WHERE i == {ZIPF_DISTRIBUTED_NUMBER};
\end{lstlisting}
    
\input{../experiments/plots/pgf/Runtime_of_ZipfDistribution.pgf}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Benchmarks: Zipf Out Of Memory (Limit 1GB)}
\begin{lstlisting}[style=SQL]
SELECT i FROM t1 
WHERE i == {ZIPF_DISTRIBUTED_NUMBER};
\end{lstlisting}
    
\input{../experiments/plots/pgf/Total_Memory_of_ZipfScanOOM.pgf}
\end{frame}


\begin{frame}[fragile]
    \frametitle{Benchmarks: Zipf Out Of Memory (Limit 1GB)}
\begin{lstlisting}[style=SQL]
SELECT i FROM t1 
WHERE i == {ZIPF_DISTRIBUTED_NUMBER};
\end{lstlisting}
    
\input{../experiments/plots/pgf/Runtime_of_ZipfScanOOM.pgf}
\end{frame}


\begin{frame}
    \frametitle{Conclusion}

    \begin{itemize}
        \item For OLAPish queries it is not (yet?) worth it, large overhead.
        \item For OLTP transactions it might be worth it. Reduces memory by $\approx 40\%$ but increases runtime by $\approx 35\%$.
        \item Huge benefit if succinct representation fits in memory vs spilling to disk.
    \end{itemize}
\end{frame}


\begin{frame}
    \frametitle{Future Work and Discussion}

    \begin{enumerate}

    \item Copying and shifting data is most time consuming (40\%) since (DuckDB) execution engine expects a 
    flat "normal" vector for OLAP queries (e.g. {\ttfamily{SELECT *}}).
    \begin{itemize}
        \item Non succinct just passes its data pointer, we need to decompress everything and copy the data.
        \item Unecessary, since we still support random access and all operations needed for the execution engine.
        \item Non succinct data pointer used everywhere in the execution engine ($>300$ appereances). \textbf{Is a major rewrite necessary?}
    \end{itemize}

    \vspace{0.3cm} 

    \item Adaptive compression for rarely accessed column segments. Zipf Distribution accesses 4 of 50 segements 
    over $>70\%$.
    \begin{itemize}
        \item How to track access statistics over time for column segments?
        \item What if the access statistics change after greater period of time?
    \end{itemize}
\end{enumerate}

\end{frame}

\end{document}
